import os
import json
import google.generativeai as genai
from typing import List, Dict, Any, Optional
from dotenv import load_dotenv

load_dotenv()

class NLPService:
    def __init__(self):
        # è®€å– GEMINI_API_KEY
        self.api_key = os.getenv("GEMINI_API_KEY")
        
        # åµæ¸¬æ˜¯å¦ç‚ºä½”ä½ç¬¦
        if self.api_key and ("your_gemini_api_key_here" in self.api_key or not self.api_key.strip()):
            print("Warning: GEMINI_API_KEY is placeholder or empty.")
            self.api_key = None
            
        if self.api_key:
            genai.configure(api_key=self.api_key)
            # ä½¿ç”¨ gemini-flash-latestï¼Œé€™é€šå¸¸æŒ‡å‘ç›®å‰ç©©å®šä¸”é…é¡å¯¬è£•çš„ç‰ˆæœ¬
            self.model_name = "gemini-flash-latest"
            self.model = genai.GenerativeModel(self.model_name)
        else:
            self.model = None

    def extract_places(self, text: str) -> List[Dict[str, Any]]:
        """
        ä½¿ç”¨ Google Gemini å¾æ–‡å­—ä¸­æŠ½å–å‡º POI åœ°é»
        """
        if not self.model:
            print("Warning: GEMINI_API_KEY not set. Returning mock extracted places.")
            return self._get_mock_extraction()

        prompt = f"""
        ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„æ—…éŠè³‡æ–™åˆ†æå¸«ã€‚è«‹åˆ†æä¸‹æ–¹çš„ç¤¾ç¾¤åª’é«”è²¼æ–‡ï¼Œä¸¦å®Œæˆä»¥ä¸‹ä»»å‹™ï¼š
        1. **æå–**ï¼šæ‰¾å‡ºæ–‡ä¸­æåˆ°çš„æ‰€æœ‰ã€Œç‰¹å®šåœ°é»ã€ã€ã€Œåº—å®¶ã€æˆ–ã€Œæ™¯é»ã€(POIs)ã€‚
        2. **æ ¡æ­£èˆ‡é©—è­‰**ï¼šåˆ©ç”¨ä½ çš„çŸ¥è­˜åº«é©—è­‰è©²åœ°é»æ˜¯å¦å­˜åœ¨ã€‚
           - è‹¥æ–‡ä¸­æ˜¯ç°¡ç¨±ï¼ˆå¦‚ã€Œé’æ²ã€ï¼‰ï¼Œè«‹æ ¡æ­£ç‚º**æ­£å¼åº—å**ï¼ˆå¦‚ã€Œé’æ² (ä¸­å±±åº—)ã€ï¼‰ã€‚
           - è‹¥æ–‡ä¸­æ˜¯éŒ¯åˆ¥å­—ï¼Œè«‹ä¿®æ­£ç‚ºæ­£ç¢ºåç¨±ã€‚
           - è‹¥è©²åœ°é»å·²æ­‡æ¥­æˆ–æ˜é¡¯ä¸å­˜åœ¨ï¼Œè«‹å¿½ç•¥è©²åœ°é»ã€‚
        
        è«‹åš´æ ¼éµå®ˆä»¥ä¸‹ JSON é™£åˆ—æ ¼å¼å›å‚³ï¼Œä¸è¦åŒ…å« Markdownï¼š
        [
            {{
                "name": "æ ¡æ­£å¾Œçš„æ­£å¼åœ°é»åç¨±",
                "category": "é¡åˆ¥(å¦‚ï¼šé¤å»³ã€å’–å•¡ã€æ™¯é»ã€å•†åº—)",
                "evidence_text": "åŸæ–‡ä¸­æåˆ°è©²åœ°é»çš„å¥å­æ®µè½",
                "confidence_score": 0.0~1.0 ä¹‹é–“çš„æ•¸å€¼ (ä»£è¡¨ä½ å°è©²åœ°é»çœŸå¯¦å­˜åœ¨çš„ä¿¡å¿ƒ)
            }}
        ]

        **é‡è¦è¦å‰‡ï¼š**
        1. **å»é‡**ï¼šå¦‚æœåŒä¸€å€‹åœ°é»å‡ºç¾å¤šæ¬¡ï¼Œè«‹åªåˆ—å‡º**æœ€ç²¾ç¢º**çš„é‚£ä¸€å€‹ã€‚
        2. **éæ¿¾éä¸»è§’**ï¼šè«‹**åªæŠ“å–é€™ç¯‡è²¼æ–‡çœŸæ­£è¦ä»‹ç´¹æˆ–æ¨è–¦çš„åœ°é»**ã€‚
           - **âŒ æ’é™¤åœ°æ¨™åƒè€ƒ**ï¼š(ä¾‹å¦‚ï¼šã€Œåœ¨ **å°åŒ—101** é™„è¿‘ã€ -> è«‹å¿½ç•¥ å°åŒ—101ï¼ŒåªæŠ“ä¸»è§’)ã€‚
           - **âŒ æ’é™¤æ¯”è¼ƒå°è±¡**ï¼š(ä¾‹å¦‚ï¼šã€Œæ¯” **é¼æ³°è±** é‚„å¥½åƒã€ -> è«‹å¿½ç•¥ é¼æ³°è±)ã€‚
           - **âŒ æ’é™¤å»£æ³›åœ°å**ï¼š(ä¾‹å¦‚ï¼šã€Œ**ä¿¡ç¾©å€** ç¾é£Ÿã€ã€ã€Œ**äº¬éƒ½** æ™¯é»ã€ -> è«‹å¿½ç•¥è¡Œæ”¿å€)ã€‚
        3. **å¯¦é«”éæ¿¾**ï¼šåªåˆ—å‡ºå…·é«”ä¸”æœ‰å¯¦é«”çš„åœ°é»æˆ–æ˜¯åº—å®¶ã€‚
        4. **æ•¸é‡**ï¼šå¯§ç¼ºå‹¿æ¿«ï¼Œå¦‚æœæ–‡ä¸­åªä»‹ç´¹ä¸€å®¶åº—ï¼Œå°±åªå›å‚³é‚£ä¸€å®¶ï¼Œä¸è¦æ¹Šæ•¸ã€‚

        è²¼æ–‡å…§å®¹ï¼š
        \"\"\"
        {text}
        \"\"\"
        """

        try:
            # Gemini ç”Ÿæˆå…§å®¹
            response = self.model.generate_content(prompt)
            print(f"ğŸ¤– [NLP] Gemini Raw Response: {response.text}") # Debug log
            content = response.text
            
            # æ¸…ç† Markdown æ¨™è¨˜ (Gemini æœ‰æ™‚æœƒåŒ… ```json ... ```)
            content = content.replace("```json", "").replace("```", "").strip()
            
            data = json.loads(content)
            
            if isinstance(data, list):
                return data
            # è‹¥ Gemini å›å‚³äº†åŒ…å« key çš„ dict
            if isinstance(data, dict):
                 # å˜—è©¦å°‹æ‰¾å¸¸è¦‹çš„ key
                 for key in ["places", "pois", "locations"]:
                     if key in data and isinstance(data[key], list):
                         return data[key]
                 # è‹¥ç„¡æ³•è­˜åˆ¥ï¼Œå›å‚³ç©ºé™£åˆ—
                 return []
            
            return []

        except Exception as e:
            print(f"NLP Extraction Error (Gemini): {e}")
            return []

    def generate_place_description(self, name: str, address: Optional[str] = None) -> str:
        """
        ä½¿ç”¨ Google Gemini ç”Ÿæˆæ™¯é»çš„ç°¡çŸ­ä»‹ç´¹ (2-3 æ®µ)
        """
        if not self.model:
            return f"{name} æ˜¯ä¸€å€‹å€¼å¾—ä¸€æ¢ç©¶ç«Ÿçš„åœ°é»ã€‚"

        prompt = f"""
        ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„æ—…éŠå°è¦½å“¡ã€‚è«‹ç‚ºä»¥ä¸‹åœ°é»æ’°å¯«ä¸€æ®µç°¡çŸ­ä¸”å¸å¼•äººçš„ä»‹ç´¹ï¼š
        åœ°é»åç¨±ï¼š{name}
        {f'åœ°å€ï¼š{address}' if address else ''}
        
        è¦æ±‚ï¼š
        1. ä½¿ç”¨ç¹é«”ä¸­æ–‡ã€‚
        2. åˆ†ç‚º 2 åˆ° 3 å€‹çŸ­å¥æˆ–æ®µè½ï¼Œç¸½å­—æ•¸æ§åˆ¶åœ¨ 100 å­—ä»¥å…§ã€‚
        3. å…§å®¹è¦åŒ…å«è©²åœ°é»çš„ç‰¹è‰²ã€æ–‡åŒ–åº•è˜Šæˆ–å¿…çœ‹ä¹‹è™•ã€‚
        4. ä¸è¦ä½¿ç”¨ Markdown æ¨™é¡Œï¼Œç›´æ¥è¼¸å‡ºæ–‡å­—å…§å®¹ã€‚
        """

        try:
            response = self.model.generate_content(prompt)
            return response.text.strip()
        except Exception as e:
            print(f"NLP Description Error (Gemini): {e}")
            return f"{name} æä¾›äº†è±å¯Œçš„é«”é©—èˆ‡ç¨ç‰¹çš„æ°›åœï¼Œæ˜¯ç•¶åœ°ç†±é–€çš„åœ°é»ä¹‹ä¸€ã€‚"

    def _get_mock_extraction(self) -> List[Dict[str, Any]]:
        return [
            {
                "name": "å°åŒ—101 (Mock Gemini)",
                "category": "æ™¯é»",
                "evidence_text": "è£¡é¢æåˆ°å°åŒ—101",
                "confidence_score": 0.99
            },
            {
                "name": "é¼æ³°è± (Mock Gemini)",
                "category": "é¤å»³",
                "evidence_text": "èˆ‡é¼æ³°è±ã€‚",
                "confidence_score": 0.98
            }
        ]
